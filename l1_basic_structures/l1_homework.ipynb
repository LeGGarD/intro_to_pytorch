{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Necessary homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2251, -0.1323, -1.5998,  1.8705, -1.8059],\n",
       "         [-1.0359, -0.2606,  0.5811,  0.4520,  0.5354],\n",
       "         [-0.9098,  0.3962,  1.2298,  1.8889,  0.1557],\n",
       "         [ 0.8910, -1.2491, -1.1928, -0.9749, -1.0453]],\n",
       "\n",
       "        [[ 0.4850, -1.2354, -0.0368, -1.6307, -0.2499],\n",
       "         [-0.8968,  0.7578,  0.3496,  0.2665, -0.0693],\n",
       "         [ 0.9668, -1.3419, -0.5262,  1.9816,  0.2943],\n",
       "         [-0.5964, -0.4167,  1.4757,  0.9589,  0.9032]],\n",
       "\n",
       "        [[ 1.1658, -0.0424,  0.6769, -0.2416,  0.8314],\n",
       "         [ 0.3790, -1.1093,  2.3114, -1.0568, -1.2111],\n",
       "         [-1.1390, -0.6333,  0.8112,  0.5545,  1.9656],\n",
       "         [-0.8900, -2.1538, -1.9405, -1.2175, -0.8657]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте случайный FloatTensor размера 3x4x5\n",
    "torch.manual_seed(95)\n",
    "x = torch.randn(3, 4, 5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выведите его форму (shape)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2251, -0.1323, -1.5998,  1.8705, -1.8059, -1.0359, -0.2606,  0.5811,\n",
       "          0.4520,  0.5354],\n",
       "        [-0.9098,  0.3962,  1.2298,  1.8889,  0.1557,  0.8910, -1.2491, -1.1928,\n",
       "         -0.9749, -1.0453],\n",
       "        [ 0.4850, -1.2354, -0.0368, -1.6307, -0.2499, -0.8968,  0.7578,  0.3496,\n",
       "          0.2665, -0.0693],\n",
       "        [ 0.9668, -1.3419, -0.5262,  1.9816,  0.2943, -0.5964, -0.4167,  1.4757,\n",
       "          0.9589,  0.9032],\n",
       "        [ 1.1658, -0.0424,  0.6769, -0.2416,  0.8314,  0.3790, -1.1093,  2.3114,\n",
       "         -1.0568, -1.2111],\n",
       "        [-1.1390, -0.6333,  0.8112,  0.5545,  1.9656, -0.8900, -2.1538, -1.9405,\n",
       "         -1.2175, -0.8657]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Приведите его к форме 6 X 10\n",
    "x = x.view(6, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X at the beginning:\n",
      "tensor([[-1.2251, -0.1323, -1.5998,  1.8705, -1.8059, -1.0359, -0.2606,  0.5811,\n",
      "          0.4520,  0.5354],\n",
      "        [-0.9098,  0.3962,  1.2298,  1.8889,  0.1557,  0.8910, -1.2491, -1.1928,\n",
      "         -0.9749, -1.0453],\n",
      "        [ 0.4850, -1.2354, -0.0368, -1.6307, -0.2499, -0.8968,  0.7578,  0.3496,\n",
      "          0.2665, -0.0693],\n",
      "        [ 0.9668, -1.3419, -0.5262,  1.9816,  0.2943, -0.5964, -0.4167,  1.4757,\n",
      "          0.9589,  0.9032],\n",
      "        [ 1.1658, -0.0424,  0.6769, -0.2416,  0.8314,  0.3790, -1.1093,  2.3114,\n",
      "         -1.0568, -1.2111],\n",
      "        [-1.1390, -0.6333,  0.8112,  0.5545,  1.9656, -0.8900, -2.1538, -1.9405,\n",
      "         -1.2175, -0.8657]])\n",
      "\n",
      "Generated vector:\n",
      "tensor([-1.0460,  1.0076,  0.4988, -2.7705,  1.5705, -1.0315,  1.4457,  0.6159,\n",
      "        -0.5116,  0.5125])\n",
      "\n",
      "Multiply each row of X by the vector:\n",
      "tensor([[ 1.2814, -0.1333, -0.7979, -5.1822, -2.8360,  1.0685, -0.3767,  0.3579,\n",
      "         -0.2312,  0.2744],\n",
      "        [ 0.9516,  0.3993,  0.6134, -5.2333,  0.2446, -0.9191, -1.8059, -0.7347,\n",
      "          0.4988, -0.5357],\n",
      "        [-0.5073, -1.2448, -0.0184,  4.5178, -0.3924,  0.9250,  1.0956,  0.2153,\n",
      "         -0.1363, -0.0355],\n",
      "        [-1.0113, -1.3522, -0.2624, -5.4899,  0.4622,  0.6152, -0.6024,  0.9088,\n",
      "         -0.4906,  0.4629],\n",
      "        [-1.2193, -0.0428,  0.3376,  0.6694,  1.3058, -0.3909, -1.6037,  1.4236,\n",
      "          0.5407, -0.6207],\n",
      "        [ 1.1913, -0.6382,  0.4046, -1.5363,  3.0870,  0.9180, -3.1137, -1.1951,\n",
      "          0.6228, -0.4437]])\n"
     ]
    }
   ],
   "source": [
    "# Умножьте его на случайный вектор размерности (1, 10) поэлементно\n",
    "y = torch.randn(10)\n",
    "z = x * y\n",
    "print(f'X at the beginning:\\n{x}\\n\\nGenerated vector:\\n{y}\\n\\nMultiply each row of X by the vector:\\n{z}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "tensor([[-1.2251, -0.1323, -1.5998,  1.8705, -1.8059, -1.0359, -0.2606,  0.5811,\n",
      "          0.4520,  0.5354],\n",
      "        [-0.9098,  0.3962,  1.2298,  1.8889,  0.1557,  0.8910, -1.2491, -1.1928,\n",
      "         -0.9749, -1.0453],\n",
      "        [ 0.4850, -1.2354, -0.0368, -1.6307, -0.2499, -0.8968,  0.7578,  0.3496,\n",
      "          0.2665, -0.0693],\n",
      "        [ 0.9668, -1.3419, -0.5262,  1.9816,  0.2943, -0.5964, -0.4167,  1.4757,\n",
      "          0.9589,  0.9032],\n",
      "        [ 1.1658, -0.0424,  0.6769, -0.2416,  0.8314,  0.3790, -1.1093,  2.3114,\n",
      "         -1.0568, -1.2111],\n",
      "        [-1.1390, -0.6333,  0.8112,  0.5545,  1.9656, -0.8900, -2.1538, -1.9405,\n",
      "         -1.2175, -0.8657]])\n",
      "\n",
      "X multiplied by itself (but transposed):\n",
      "tensor([[12.8071,  0.0557, -1.9528,  5.5107, -4.3454, -2.9893],\n",
      "        [ 0.0557, 11.9097, -6.4453, -1.9197,  0.6906,  9.4403],\n",
      "        [-1.9528, -6.4453,  6.0608, -0.2308,  0.2091, -2.9722],\n",
      "        [ 5.5107, -1.9197, -0.2308, 11.4677,  2.1336, -2.3855],\n",
      "        [-4.3454,  0.6906,  0.2091,  2.1336, 11.8691,  0.6502],\n",
      "        [-2.9893,  9.4403, -2.9722, -2.3855,  0.6502, 17.9558]])\n"
     ]
    }
   ],
   "source": [
    "# Умножьте тензор матрично на себя, чтобы результат был размерности 6x6\n",
    "x_matmulted = torch.matmul(x, x.T)\n",
    "print(f'X:\\n{x}\\n\\nX multiplied by itself (but transposed):\\n{x_matmulted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-65"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посчитайте производную функции y = x**3 + z - 75t в точке (1, 0.5, 2)\n",
    "x, z, t = (1, 0.5, 2)\n",
    "y = x**3 + z - 75*t\n",
    "y_der = (3*x)**2 + 1 - 75\n",
    "y_der"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте единичный тензор размера 5x6\n",
    "x_ones = torch.ones(5, 6)\n",
    "x_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Переведите его в формат numpy\n",
    "x_ones.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Поддерживается ли CUDA : False\n",
      "Количество гпу девайсов: 0\n",
      ":(\n"
     ]
    }
   ],
   "source": [
    "print(f\"Поддерживается ли CUDA : {torch.cuda.is_available()}\")\n",
    "print(f'Количество гпу девайсов: {torch.cuda.device_count()}')\n",
    "print(f\":(\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional tasks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Creating a fully connected layer with n_neurons.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an input vector of a random size.  \n",
    "Set any number of neurons in the hidden layer.  \n",
    "And set the output to 1 neuron. So it's meant to be a single scalar (let's pretend it's a regression task). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 5  # size of the input vector\n",
    "n_neurons_1 = 10  # number of neurons in a hidden layer\n",
    "n_neurons_2 = 1  # number of neurons in the output layer\n",
    "\n",
    "# input vector\n",
    "x = torch.rand(n_features)\n",
    "\n",
    "# layer 1 weights + bias\n",
    "w1 = torch.rand(n_neurons_1, n_features, requires_grad=True)\n",
    "b1 = torch.rand(n_neurons_1, requires_grad=True)\n",
    "\n",
    "# layer 1 forward pass\n",
    "activation_function = torch.sigmoid\n",
    "layer_1 = activation_function((x * w1).sum(dim=1) + b1)\n",
    "\n",
    "# output layer weights + bias\n",
    "w2 = torch.rand(n_neurons_2, n_neurons_1, requires_grad=True)\n",
    "b2 = torch.rand(n_neurons_2, requires_grad=True)\n",
    "\n",
    "# output layer results\n",
    "activation_function = torch.relu\n",
    "\n",
    "output = activation_function((layer_1 * w2).sum(dim=1) + b2)\n",
    "\n",
    "# mock the loss\n",
    "L = (10 - output)\n",
    "\n",
    "# do backpropagation step\n",
    "L.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients for the Weight Matrix 1:\n",
      "tensor([[-0.0654, -0.0765, -0.0420, -0.0527, -0.0145],\n",
      "        [-0.0423, -0.0495, -0.0272, -0.0341, -0.0094],\n",
      "        [-0.0136, -0.0159, -0.0087, -0.0109, -0.0030],\n",
      "        [-0.0600, -0.0702, -0.0386, -0.0483, -0.0133],\n",
      "        [-0.1116, -0.1305, -0.0717, -0.0899, -0.0248],\n",
      "        [-0.0113, -0.0132, -0.0072, -0.0091, -0.0025],\n",
      "        [-0.0261, -0.0306, -0.0168, -0.0210, -0.0058],\n",
      "        [-0.0011, -0.0012, -0.0007, -0.0009, -0.0002],\n",
      "        [-0.0455, -0.0532, -0.0293, -0.0367, -0.0101],\n",
      "        [-0.0501, -0.0586, -0.0322, -0.0404, -0.0111]])\n",
      "\n",
      "Gradients for the Bias Vector 1:\n",
      "tensor([0.1969, 0.7229, 0.8916, 0.3135, 0.2281, 0.3442, 0.6012, 0.8099, 0.7866,\n",
      "        0.8336], requires_grad=True)\n",
      "\n",
      "Gradients for the Weight Matrix 2:\n",
      "tensor([[-0.8589, -0.9268, -0.9563, -0.7424, -0.7839, -0.7830, -0.8072, -0.8309,\n",
      "         -0.8473, -0.9058]])\n",
      "\n",
      "Gradients for the Bias Vector 2:\n",
      "tensor([0.6832], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(f'Gradients for the Weight Matrix 1:\\n{w1.grad}\\n\\nGradients for the Bias Vector 1:\\n{b1}'\n",
    "      f'\\n\\nGradients for the Weight Matrix 2:\\n{w2.grad}\\n\\nGradients for the Bias Vector 2:\\n{b2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results:\n",
    "This way we can calculate gradients manually. With a bit of time it's easy to implement learning rate here, make a for loop, and train the very basic model for a few epochs, measuring the loss on each step :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Torch Layers intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.1916\n",
      "loss: 0.2081\n",
      "loss: 0.2255\n",
      "loss: 0.2434\n",
      "loss: 0.2614\n",
      "loss: 0.2792\n",
      "loss: 0.2964\n",
      "loss: 0.3127\n",
      "loss: 0.3276\n",
      "loss: 0.3410\n"
     ]
    }
   ],
   "source": [
    "# Super basec imitation of a perceptron with a torch Linear layer\n",
    "# A fully connected layer, trained for n_epochs, measuring the loss\n",
    "\n",
    "layer = torch.nn.Linear(\n",
    "    in_features=5,\n",
    "    out_features=10,\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(layer_1.parameters(), lr=0.01)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "X = torch.rand(5)\n",
    "y = torch.rand(10)\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    predictions = layer_1(X)\n",
    "    loss = loss_func(predictions, y)\n",
    "    print(f'loss: {loss:.4f}')\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
